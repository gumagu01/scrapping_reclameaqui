{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import httplib2\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import date \n",
    "import xlsxwriter\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_csv(path):\n",
    "    with open(path, encoding='utf-8') as f:\n",
    "        a = [{str(k):str(v) for k, v in row.items()}\n",
    "            for row in csv.DictReader(f, skipinitialspace=True)]\n",
    "    return a\n",
    "\n",
    "def extract_source(url):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:50.0) Gecko/20100101 Firefox/50.0'}\n",
    "    source=requests.get(url, headers=headers).text\n",
    "    content = json.loads(source)\n",
    "    return content\n",
    "\n",
    "def extract(url):\n",
    "    i=0\n",
    "    content=1\n",
    "    while content:\n",
    "        try:\n",
    "            url = 'https://iosearch.reclameaqui.com.br/raichu-io-site-search-v1/query/companyComplains/10/{}?company=2010&evaluated=bool:'.format(str(10*i))\n",
    "            content = extract_source(url)\n",
    "\n",
    "            if not content:\n",
    "                break\n",
    "            i=i+1\n",
    "            for item in content[\"complainResult\"][\"complains\"][\"data\"]:\n",
    "                add = {'Title':item['title'],'Complain': item['description'],'Score':item['score'],'DealAgain':item['dealAgain'],'Status':item['status'], 'FirstInteraction':item[\"firstInteractionDate\"]}\n",
    "                df = df.append(add, ignore_index=True)\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def splitter(data1):\n",
    "    data1 = data1.split('T')[0]\n",
    "\n",
    "    return data1\n",
    "\n",
    "def splitter2(data1,data2):\n",
    "    data1 = data1.split('T')[0]\n",
    "    data2 = data2.split('.')[0]\n",
    "    return pd.Series([data1,data2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(company):\n",
    "    dfava = pd.DataFrame(columns=['Title','Complain','Type','Score','DealAgain','Status', 'Created'])\n",
    "    dfans = pd.DataFrame(columns=['Title','Complain','Type','Score','DealAgain','Status','Created'])\n",
    "    dfpen=pd.DataFrame(columns=['Title','Complain','Type','Score','DealAgain','Status', 'Created'])\n",
    "    i=0\n",
    "    content=1\n",
    "    while content:\n",
    "        try:\n",
    "            urlans = 'https://iosearch.reclameaqui.com.br/raichu-io-site-search-v1/query/companyComplains/10/{}?company={}&evaluated=bool:'.format(str(10*i),company)\n",
    "            content = extract_source(urlans)\n",
    "\n",
    "            if not content:\n",
    "                break\n",
    "            i=i+1\n",
    "            for item in content[\"complainResult\"][\"complains\"][\"data\"]:\n",
    "                add = {'Title':item['title'],'Complain': item['description'],'Type':item['otherProblemType'],'Score':item['score'],'DealAgain':item['dealAgain'],'Status':item['status'], 'Created':item['created']}\n",
    "                dfava = dfava.append(add, ignore_index=True)\n",
    "        except:\n",
    "            break\n",
    "    content=1\n",
    "    i=0\n",
    "    while content:\n",
    "        try:\n",
    "            urlans = 'https://iosearch.reclameaqui.com.br/raichu-io-site-search-v1/query/companyComplains/10/{}?company={}&status=ANSWERED&evaluated=bool:false'.format(str(10*i),company)\n",
    "            content = extract_source(urlans)\n",
    "\n",
    "            if not content:\n",
    "                break\n",
    "            i=i+1\n",
    "            for item in content[\"complainResult\"][\"complains\"][\"data\"]:\n",
    "                add = {'Title':item['title'],'Complain': item['description'],'Type':item['otherProblemType'],'Score':item['score'],'DealAgain':item['dealAgain'],'Status':item['status'], 'Created':item['created']}\n",
    "                dfans = dfans.append(add, ignore_index=True)\n",
    "        except:\n",
    "            break\n",
    "    content=1\n",
    "    i=0\n",
    "    while content:\n",
    "        try:\n",
    "            urlpen = 'https://iosearch.reclameaqui.com.br/raichu-io-site-search-v1/query/companyComplains/10/{}?company={}&status=PENDING&evaluated=bool:false'.format(str(10*i),company)\n",
    "            content = extract_source(urlpen)\n",
    "\n",
    "            if not content:\n",
    "                break\n",
    "            i=i+1\n",
    "            for item in content[\"complainResult\"][\"complains\"][\"data\"]:\n",
    "                add = {'Title':item['title'],'Complain': item['description'],'Type':item['otherProblemType'],'Score':item['score'],'DealAgain':item['dealAgain'],'Status':item['status'], 'Created':item['created']}\n",
    "                dfpen = dfpen.append(add, ignore_index=True)\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    dfpen['Created'] = dfpen.apply(lambda row : splitter(str(row['Created'])), axis = 1)\n",
    "    dfans['Created'] = dfans.apply(lambda row : splitter(str(row['Created'])), axis = 1)\n",
    "    dfava[['Created','Score']] = dfava.apply(lambda row : splitter2(str(row['Created']),str(row['Score'])), axis = 1)            \n",
    "    return dfpen,dfans,dfava\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results(dfpen,dfans,dfava,empresa):\n",
    "\n",
    "    dfpen.to_csv(\"./results/{}/NaoRespondidas{}.csv\".format(empresa,empresa))\n",
    "\n",
    "    dfava.to_csv(\"./results/{}/Avaliadas{}.csv\".format(empresa,empresa))\n",
    "\n",
    "    dfans.to_csv(\"./results/{}/Respondidas{}.csv\".format(empresa,empresa))\n",
    "\n",
    "empresas = read_csv(\"empresas.csv\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for empresa in empresas:\n",
    "    dfpen,dfans,dfava = data(empresa[\"Codigo\"])\n",
    "    write_results(dfpen,dfans,dfava,empresa[\"Empresas\"])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "395b8b1a245bd4232c60211d501b4c6c8b458ee5aedb01629aceb709b5577add"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('venv': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
